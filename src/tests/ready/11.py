import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFilter
from tensorflow.keras.models import Sequential, load_model # type: ignore
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout # type: ignore
from tensorflow.keras.utils import to_categorical # type: ignore
from data.config import train_data_folder, emnist_labels  # Пути к данным

# Функция загрузки данных
def load_emnist_data(data_path):
    """Загружает и подготавливает данные EMNIST"""
    print(f'Загрузка данных из {data_path}...')
    df = pd.read_csv(data_path, header=None)
    y = df.iloc[:, 0].values  # Метки классов (первый столбец)
    X = df.iloc[:, 1:].values  # Остальные столбцы - пиксели
    X = X.reshape(-1, 28, 28, 1).astype("float32") / 255.0  # Нормализация
    return X, y
# Визуализация нескольких изображений из датасета
def show_sample_images(X, y, num_samples=5):
    t = 0
    for i in range(len(X)):
        if(y[i] == 10):
            image = X[i].reshape(28, 28).T  # Преобразуем в 28x28 (EMNIST использует этот размер)
            plt.imshow(image, cmap='gray')
            plt.title(f"Тестовое изображение, метка: {y[i]} - {emnist_labels[y[i]]}")
            plt.show()
            t += 1
        if t == num_samples:
            break


# Пути к файлам
train_file = f"{train_data_folder}\\emnist-byclass-train.csv"
test_file = f"{train_data_folder}\\emnist-byclass-test.csv"
model_file = "emnist_cnn_model.h5"
# # Загружаем данные
# X_train, y_train = load_emnist_data(train_file)
# X_test, y_test = load_emnist_data(test_file)
# # Преобразуем метки классов в one-hot encoding
# num_classes = len(set(y_train))  # Определяем количество классов
# y_train_categorical = to_categorical(y_train, num_classes=num_classes)
# y_test_categorical = to_categorical(y_test, num_classes=num_classes)

# # show_sample_images(X_train, y_train)
# # Создание нейросети
# model = Sequential([
#     Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
#     MaxPooling2D((2, 2)),
#     Conv2D(64, (3, 3), activation='relu'),
#     MaxPooling2D((2, 2)),
#     Flatten(),
#     Dense(128, activation='relu'),
#     Dropout(0.5),
#     Dense(num_classes, activation='softmax')
# ])

# # Компиляция модели
# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# # Обучение модели
# print("Начинаем обучение...")
# model.fit(X_train, y_train_categorical, epochs=10, batch_size=128, validation_data=(X_test, y_test_categorical))
# # Оценка точности на тестовых данных
# test_loss, test_acc = model.evaluate(X_test, y_test_categorical)
# print(f'Точность на тестовых данных: {test_acc:.4f}')
# # Сохранение модели
# model.save("emnist_cnn_model.h5")
# print("Модель сохранена.")


def predict_image(image_path, model):
    """
    Загружает изображение, подготавливает его для модели и делает предсказание.
    """
    image = Image.open(image_path).convert('L')
    image = image.resize((28, 28))  # Приводим к стандартному размеру

    # Преобразуем в numpy-массив и нормализуем
    image = np.array(image) / 255.0
    image = image.reshape(1, 28, 28, 1)  # Приводим к формату модели

    # Визуализируем изображение перед подачей в модель
    plt.imshow(image.reshape(28, 28), cmap='gray')
    plt.title("Изображение перед предсказанием")
    plt.axis("off")
    plt.show()

    # Делаем предсказание
    prediction = model.predict(image)
    predicted_label = np.argmax(prediction)  # Индекс класса с наибольшей вероятностью
    confidence = np.max(prediction)  # Уверенность предсказания

    # Выводим результат
    print(f"Предсказанный символ: {emnist_labels.get(predicted_label, '?')} ({predicted_label})  (уверенность {confidence:.2f})")
    return emnist_labels.get(predicted_label, '?'), confidence  

def create_and_save_image(coords, model, filename="symbol.png"):
    """
    Создает изображение из набора координат и предсказывает символ.
    """
    if not coords:
        print("Ошибка: список координат пуст!")
        return None

    # Определяем границы символа
    x_coords, y_coords = zip(*coords)
    x_min, x_max = min(x_coords), max(x_coords)
    y_min, y_max = min(y_coords), max(y_coords)

    # Масштабируем координаты в диапазон (0, 27)
    scale = max(x_max - x_min, y_max - y_min)
    if scale == 0:
        print("Ошибка: символ слишком маленький!")
        return None

    norm_coords = [
        ((x - x_min) / scale * 27, (y - y_min) / scale * 27)
        for x, y in coords
    ]

    # Создаём 28x28 изображение (чёрный фон)
    image = Image.new("L", (28, 28), 0)
    draw = ImageDraw.Draw(image)

    # Рисуем точки (белым цветом)
    for x, y in norm_coords:
        draw.ellipse((x, y, x + 1, y + 1), fill=255)

    # Применяем размытие для естественности
    image = image.filter(ImageFilter.GaussianBlur(1))

    # Сохраняем изображение
    image.save(filename)
    print(f"Изображение сохранено как {filename}")

    # Визуализируем
    plt.imshow(image, cmap='gray')
    plt.axis("off")
    plt.show()

    # Предсказание
    return predict_image(filename, model)


# Загружаем модель
model = load_model("emnist_cnn_model.h5")

# Тестовый набор координат
coords = [(213, 231), (200, 214), (196, 201), (197, 193), (197, 192), (197, 193), (195, 193), (194, 192), (194, 192), (194, 193), (193, 192), (193, 190), (194, 189), (194, 186), (194, 187), (195, 185), (195, 183), (204, 166), (210, 160), (215, 154), (221, 139), (220, 138), (228, 134), (235, 125), (238, 125), (263, 82), (265, 72), (272, 58), (273, 59), (274, 52), (276, 45), (275, 45), (281, 40), (281, 40), (284, 41), (283, 42), (284, 44), (287, 50), (286, 51), (294, 72), (297, 78), (297, 91), (297, 90), (307, 119), (312, 125), (319, 132), (319, 132), (323, 135), (325, 138), (325, 139), (333, 147), (334, 148), (336, 147), (336, 147), (339, 146), (345, 133), (349, 128), (353, 120), (360, 104), (358, 105), (363, 95), (370, 70), (373, 55), (374, 48), (377, 40), (376, 40), (379, 37), (378, 36), (386, 37), (388, 41), (394, 47), (396, 54), (399, 59), (403, 64), (413, 84), (424, 99), (425, 99), (431, 105), (439, 124), (448, 158), (452, 166), (454, 171), (456, 180), (457, 180), (458, 185), (459, 184), (466, 196), (468, 199), (468, 199), (470, 200), (0, 320), (472, 201), (471, 200), (472, 199), (472, 198), (471, 197), (473, 195), (471, 193), (471, 192), (471, 191)]

image_data = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,255,255,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,255,255,255,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])


# image_data = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,81,125,77,0,0,0,0,0,0,1,19,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,159,232,249,206,10,0,0,0,0,0,34,201,207,90,1,0,0,0,0,0,0,0,0,0,0,0,24,170,254,254,254,253,113,4,0,0,0,0,84,233,253,218,19,0,0,0,0,0,0,0,0,0,2,11,131,234,254,255,255,254,127,4,0,0,0,2,170,251,254,233,20,0,0,0,0,0,0,0,0,0,66,139,244,254,255,255,255,254,127,4,0,0,0,2,173,252,254,217,4,0,0,0,0,0,0,0,7,59,232,254,254,254,254,254,255,254,129,5,0,0,0,2,174,252,254,217,4,0,0,0,0,0,0,0,90,207,254,254,254,236,236,254,255,254,170,20,0,0,0,4,217,254,254,217,4,0,0,0,0,0,7,36,221,254,254,247,202,79,129,250,255,254,140,9,0,0,0,4,217,254,254,222,9,0,0,0,0,1,90,203,249,254,245,164,34,7,127,250,255,254,129,5,0,0,0,4,217,254,254,249,37,0,0,0,6,79,245,254,254,250,95,9,0,0,125,249,255,254,203,32,0,0,0,4,203,254,255,250,37,0,0,3,111,189,254,254,251,187,20,0,0,0,82,232,254,254,217,39,0,0,0,0,129,250,255,250,39,0,3,79,247,254,254,251,131,32,0,0,0,0,8,127,254,255,229,70,0,0,0,0,114,245,255,252,82,3,48,176,254,254,253,218,23,0,0,0,0,0,0,51,250,255,234,84,0,0,0,0,38,216,254,254,148,100,244,254,254,246,127,33,0,0,0,0,0,0,0,32,245,254,250,127,0,0,0,0,21,172,254,254,236,235,254,254,250,175,10,0,0,0,0,0,0,0,0,9,220,254,250,140,0,0,0,0,4,125,254,255,255,255,254,251,100,20,0,0,0,0,0,0,0,0,0,0,109,239,253,184,3,0,0,0,2,82,252,254,255,254,253,218,22,0,0,0,0,0,0,0,0,0,0,0,115,245,254,205,4,0,0,0,0,34,243,254,255,254,221,91,1,0,0,0,0,0,0,0,0,0,0,0,109,232,254,217,4,0,0,0,0,1,123,232,253,232,78,3,0,0,0,0,0,0,0,0,0,0,0,0,4,79,213,153,2,0,0,0,0,0,22,126,202,95,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,36,20,0,0,0,0,0,0,0,2,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])
image_data = image_data.reshape(28, 28)
# Нормализация
image_data = image_data.astype("float32") / 255.0
# Добавляем размерность канала (для Conv2D)
image_data = np.expand_dims(image_data, axis=-1)  # (28, 28, 1)
# Добавляем размерность batch (т.к. модель ожидает (batch_size, 28, 28, 1))
image_data = np.expand_dims(image_data, axis=0)  # (1, 28, 28, 1)
# Проверяем размерность перед подачей в модель
prediction = model.predict(image_data.T)  # Получаем вектор предсказаний
# Индекс с наибольшей вероятностью - это и есть буква
predicted_class = np.argmax(prediction)
print(f"Предсказанная буква: {predicted_class}")

image = image_data.reshape(28, 28)  # Преобразуем в 28x28 (EMNIST использует этот размер)
plt.imshow(image, cmap='gray')
plt.title(f"Тестовое изображение, метка: {predicted_class} - {emnist_labels[predicted_class]} ({np.max(prediction)})")
plt.show()
